{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"markdown","source":"using Efficientnet","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet wandb","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:10.804387Z","iopub.execute_input":"2022-04-09T11:36:10.804639Z","iopub.status.idle":"2022-04-09T11:36:18.262096Z","shell.execute_reply.started":"2022-04-09T11:36:10.804609Z","shell.execute_reply":"2022-04-09T11:36:18.261237Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport math, random, re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow_addons.metrics import F1Score\n\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import KFold\n\nimport efficientnet.tfkeras as efn\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport wandb\nfrom wandb.integration.keras import WandbCallback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-09T11:36:18.264339Z","iopub.execute_input":"2022-04-09T11:36:18.264601Z","iopub.status.idle":"2022-04-09T11:36:18.274658Z","shell.execute_reply.started":"2022-04-09T11:36:18.264574Z","shell.execute_reply":"2022-04-09T11:36:18.273806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret('wandb_key')\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    wandb.login(anonymous='must')\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your \\\n           W&B access token. Use the Label name as WANDB. \\nGet your W&B access \\\n           token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.276086Z","iopub.execute_input":"2022-04-09T11:36:18.277752Z","iopub.status.idle":"2022-04-09T11:36:18.574257Z","shell.execute_reply.started":"2022-04-09T11:36:18.277720Z","shell.execute_reply":"2022-04-09T11:36:18.573533Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.575485Z","iopub.execute_input":"2022-04-09T11:36:18.575722Z","iopub.status.idle":"2022-04-09T11:36:18.583224Z","shell.execute_reply.started":"2022-04-09T11:36:18.575690Z","shell.execute_reply":"2022-04-09T11:36:18.582420Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Configurations\n\nSetting image size to 224x224 and no of epochs to 20.","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\nIMAGE_SIZE = 224\nEPOCHS = 20\n\nSEED = 6969\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nCLASSES = [0,1]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.585562Z","iopub.execute_input":"2022-04-09T11:36:18.586139Z","iopub.status.idle":"2022-04-09T11:36:18.592423Z","shell.execute_reply.started":"2022-04-09T11:36:18.586101Z","shell.execute_reply":"2022-04-09T11:36:18.591495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Mixed Precision - XLA","metadata":{}},{"cell_type":"code","source":"MIXED_PRECISION = True\nXLA_ACCELERATE = True\n\nif MIXED_PRECISION:\n    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    mixed_precision.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.593885Z","iopub.execute_input":"2022-04-09T11:36:18.594297Z","iopub.status.idle":"2022-04-09T11:36:18.605813Z","shell.execute_reply.started":"2022-04-09T11:36:18.594261Z","shell.execute_reply":"2022-04-09T11:36:18.605081Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n\n* zooming and shifting the image \n* random flip left and right\n* random brightness\n* random contrast\n* random saturation","metadata":{}},{"cell_type":"code","source":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n\ndef transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image, label):\n\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=0.1, seed=69)\n    image = tf.image.random_contrast(image, 0.8, 1.0)\n    image = tf.image.random_saturation(image, 1, 2)\n\n    return image, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading dataset","metadata":{}},{"cell_type":"code","source":"train_path_0 = '../input/car-damage-detection/data1a/training/00-damage/*'\ntrain_path_1 = '../input/car-damage-detection/data1a/training/01-whole/*'\n\ntrain_0 = sorted(glob(train_path_0))\ntrain_1 = sorted(glob(train_path_1))\n\nprint(len(train_0), len(train_1))\n\nval_path_0 = '../input/car-damage-detection/data1a/validation/00-damage/*'\nval_path_1 = '../input/car-damage-detection/data1a/validation/01-whole/*'\n\nvalid_0 = sorted(glob(val_path_0))\nvalid_1 = sorted(glob(val_path_1))\n\nprint(len(valid_0), len(valid_1))\n\nmap_train = {}\nmap_val = {}\nfor i in range(len(train_0)):\n    map_train[train_0[i]] = 0\n\nfor i in range(len(train_1)):\n    map_train[train_1[i]] = 1\n    \nfor i in range(len(valid_0)):\n    map_val[valid_0[i]] = 0\n\nfor i in range(len(valid_1)):\n    map_val[valid_1[i]] = 1","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.671181Z","iopub.execute_input":"2022-04-09T11:36:18.671662Z","iopub.status.idle":"2022-04-09T11:36:18.710886Z","shell.execute_reply.started":"2022-04-09T11:36:18.671624Z","shell.execute_reply":"2022-04-09T11:36:18.710140Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Utitlity function to create tf.dataset\n\nUsing tf.dataset to generate dataset","metadata":{}},{"cell_type":"code","source":"def decode_image(filename):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n    return image\n\ndef get_labels_from_filenames(filenames, train):\n    if train:\n        labels = []\n        for name in filenames:\n\n            labels.append(map_train[name])\n        labels = tf.keras.utils.to_categorical(\n        labels, num_classes=len(CLASSES), dtype='float32'\n    )\n        \n    else:\n        labels = []\n        for name in filenames:\n\n            labels.append(map_val[name])\n        labels = tf.keras.utils.to_categorical(\n        labels, num_classes=len(CLASSES), dtype='float32'\n    )\n    return labels\n\ndef load_dataset(path_0, path_1, train):\n    \n    filenames = tf.io.gfile.glob(path_0) + tf.io.gfile.glob(path_1)\n    random.shuffle(filenames)\n    rnd_labels = get_labels_from_filenames(filenames, train)\n    \n    DATASET_SIZE = len(filenames)\n    print(len(filenames))\n\n    filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n    images_ds = filenames_ds.map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    labels_ds = tf.data.Dataset.from_tensor_slices(rnd_labels)\n    dataset = tf.data.Dataset.zip((images_ds, labels_ds))\n        \n    return dataset, DATASET_SIZE\n\ndef get_training_and_validation_dataset():\n    train_ds, TRAIN_DS_SIZE = load_dataset(train_path_0, train_path_1, train = True)\n\n    train_ds = train_ds.map(data_augment, num_parallel_calls=AUTO)\n    train_ds = train_ds.map(transform, num_parallel_calls=AUTO)\n    \n    train_ds = train_ds.repeat()\n    train_ds = train_ds.batch(BATCH_SIZE)\n    train_ds = train_ds.prefetch(AUTO)\n    \n    val_ds, VAL_DS_SIZE = load_dataset(val_path_0, val_path_1, train = False)\n    \n    val_ds = val_ds.batch(BATCH_SIZE)\n    val_ds = val_ds.cache()\n    val_ds = val_ds.prefetch(AUTO)\n    \n    return train_ds, TRAIN_DS_SIZE, val_ds, VAL_DS_SIZE","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.712211Z","iopub.execute_input":"2022-04-09T11:36:18.712678Z","iopub.status.idle":"2022-04-09T11:36:18.727589Z","shell.execute_reply.started":"2022-04-09T11:36:18.712643Z","shell.execute_reply":"2022-04-09T11:36:18.726874Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(len(train_0)+len(train_1), len(map_train))\nprint(len(valid_0)+len(valid_1), len(map_val))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:18.731589Z","iopub.execute_input":"2022-04-09T11:36:18.732302Z","iopub.status.idle":"2022-04-09T11:36:18.740256Z","shell.execute_reply.started":"2022-04-09T11:36:18.732272Z","shell.execute_reply":"2022-04-09T11:36:18.739527Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the augmentations","metadata":{}},{"cell_type":"code","source":"for i in range(5):\n    row = 3; col = 4;\n    train_ds, NUM_TRAINING_IMAGES, val_ds, NUM_VALIDATION_IMAGES = get_training_and_validation_dataset()\n    all_elements = train_ds.unbatch()\n    one_element = tf.data.Dataset.from_tensors(next(iter(all_elements)) )\n    one_element_ = tf.data.Dataset.from_tensors(next(iter(all_elements)) )\n    augmented_element = one_element_.repeat().map(data_augment).batch(row*col)\n\n    for (img,label) in augmented_element:\n        plt.figure(figsize=(15,int(15*row/col)))\n        for j in range(row*col):\n            plt.subplot(row,col,j+1)\n            plt.axis('off')\n            plt.imshow(img[j,])\n        plt.show()\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:20.521677Z","iopub.execute_input":"2022-04-09T11:36:20.522101Z","iopub.status.idle":"2022-04-09T11:36:28.833784Z","shell.execute_reply.started":"2022-04-09T11:36:20.522061Z","shell.execute_reply":"2022-04-09T11:36:28.833006Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Train and Infer\n\nLearning rate schedule as using an high LR would break the pre-trained weights so, ramp up is utilized to fine-tune a pre-trained model.","metadata":{}},{"cell_type":"code","source":"LR_START = 0.00001/2.0\nLR_MAX = 0.00001 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001/2.0\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n\nrng = [i for i in range(25 if EPOCHS<25 else EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:28.835650Z","iopub.execute_input":"2022-04-09T11:36:28.835941Z","iopub.status.idle":"2022-04-09T11:36:29.024256Z","shell.execute_reply.started":"2022-04-09T11:36:28.835905Z","shell.execute_reply":"2022-04-09T11:36:29.022900Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Training the model\n\n* optimizer - ADAM\n* loss - Binary Crossentropy (as it is binary classification)\n* metrics - accuracy","metadata":{}},{"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nfrom tensorflow.keras.applications import DenseNet201\n\ndef get_model():\n    with strategy.scope():\n        rnet = efn.EfficientNetB7(\n            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n            weights='noisy-student',\n            include_top=False\n        )\n        rnet.trainable = True\n        model = tf.keras.Sequential([\n            rnet,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(len(CLASSES), activation='softmax',dtype='float32')\n        ])\n    model.compile(\n        optimizer='adam',\n        loss = 'BinaryCrossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\ndef train_and_validate():\n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n        \n    train_ds, NUM_TRAINING_IMAGES, val_ds, NUM_VALIDATION_IMAGES = get_training_and_validation_dataset()\n\n    model = get_model()\n    wandb.init(project='Task 2.1 car-scan', job_type='train', reinit=True)\n    log_callback = WandbCallback()\n    history = model.fit(\n        train_ds, \n        steps_per_epoch = STEPS_PER_EPOCH,\n        epochs = EPOCHS,\n        callbacks = [lr_callback, log_callback, early_stopping],\n        validation_data = val_ds,\n        verbose=1\n    )\n    wandb.finish()\n    return history, model\n\ndef train_():\n\n    history, model = train_and_validate()\n    return history, model\n    \n# run train and predict\nhistory, model = train_()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:42.330409Z","iopub.execute_input":"2022-04-09T11:36:42.330664Z","iopub.status.idle":"2022-04-09T12:01:52.997963Z","shell.execute_reply.started":"2022-04-09T11:36:42.330635Z","shell.execute_reply":"2022-04-09T12:01:52.997280Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.save('./model')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:29.451647Z","iopub.status.idle":"2022-04-09T11:36:29.452213Z","shell.execute_reply.started":"2022-04-09T11:36:29.451966Z","shell.execute_reply":"2022-04-09T11:36:29.451993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nmodel = keras.models.load_model('./model')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:29.453437Z","iopub.status.idle":"2022-04-09T11:36:29.453986Z","shell.execute_reply.started":"2022-04-09T11:36:29.453744Z","shell.execute_reply":"2022-04-09T11:36:29.453767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:29.455027Z","iopub.status.idle":"2022-04-09T11:36:29.455591Z","shell.execute_reply.started":"2022-04-09T11:36:29.455357Z","shell.execute_reply":"2022-04-09T11:36:29.455381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:29.456656Z","iopub.status.idle":"2022-04-09T11:36:29.457190Z","shell.execute_reply.started":"2022-04-09T11:36:29.456969Z","shell.execute_reply":"2022-04-09T11:36:29.456992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('./model', 'zip', './model')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:36:29.458146Z","iopub.status.idle":"2022-04-09T11:36:29.458850Z","shell.execute_reply.started":"2022-04-09T11:36:29.458602Z","shell.execute_reply":"2022-04-09T11:36:29.458627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}